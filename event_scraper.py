# -*- coding: utf-8 -*-
"""event_scraper.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LkTsPIMeA61jJgqnJ3dMYzLQZAXsXA9F
"""

import feedparser
import pandas as pd
from datetime import datetime
import nltk
from nltk.sentiment import SentimentIntensityAnalyzer

# Download VADER lexicon if not present
try:
    nltk.data.find('sentiment/vader_lexicon.zip')
except LookupError:
    nltk.download('vader_lexicon')

# Initialize VADER
sia = SentimentIntensityAnalyzer()

# Industry mapping
industry_map = {
    "AAPL": "Tech", "ABBV": "Pharma", "AMZN": "Retail", "BA": "Aerospace", "BMY": "Pharma",
    "CVX": "Energy", "F": "Auto", "GE": "Industrial", "GM": "Auto", "INTC": "Tech",
    "JNJ": "Pharma", "JPM": "Banking", "MRK": "Pharma", "MS": "Banking", "NVDA": "Tech",
    "PFE": "Pharma", "TSLA": "Auto", "TSM": "Tech", "WMT": "Retail", "XOM": "Energy"
}

# Classify news type
def classify_news_type(headline):
    headline = headline.lower()
    if "earnings" in headline or "q1" in headline or "q2" in headline:
        return "Earnings"
    elif "tariff" in headline or "sanction" in headline or "trade war" in headline:
        return "Tariff"
    elif "lawsuit" in headline or "investigation" in headline:
        return "Legal Issue"
    elif "merger" in headline or "acquisition" in headline:
        return "M&A"
    else:
        return "General News"

# VADER sentiment scoring
def get_sentiment_vader(headline):
    score = sia.polarity_scores(headline)
    if score['compound'] >= 0.05:
        return "Positive"
    elif score['compound'] <= -0.05:
        return "Negative"
    else:
        return "Neutral"

# Scraper function
def get_live_events():
    tickers = list(industry_map.keys())
    records = []

    for ticker in tickers:
        query = f"{ticker} stock"
        rss_url = f"https://news.google.com/rss/search?q={query.replace(' ', '+')}&hl=en-US&gl=US&ceid=US:en"
        feed = feedparser.parse(rss_url)

        for entry in feed.entries:
            try:
                date = datetime(*entry.published_parsed[:6])
            except:
                continue

            headline = entry.title

            # ðŸ›‘ Filter out stock-focused headlines
            if any(keyword in headline.lower() for keyword in ["stock", "share price","shares"]):
                continue

            records.append({
                "ticker": ticker,
                "headline": headline,
                "event_date": date,
                "link": entry.link,
                "news_type": classify_news_type(headline),
                "sentiment": get_sentiment_vader(headline),
                "industry": industry_map.get(ticker, "Unknown")
            })

    df = pd.DataFrame(records)
    df = df.dropna(subset=["event_date"])
    df = df.sort_values(by="event_date", ascending=False).reset_index(drop=True)
    df = df[df["news_type"] == "Tariff"]

    # ðŸ§  Limit to 1000 most recent
    df = df.head(1000)

    return df
